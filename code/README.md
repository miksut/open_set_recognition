# Source Code

The source code is organised in form of two Python packages: _eosa_ (Evaluation of Open Set Algorithms) and _imageNet_protocols_. The package _eosa_ contains all the experimental functionality. Most importantly, the module _experiments_ contains files and scripts that are necessary to configure and execute the algorithms. This procedure is described below. The package _imageNet_protocols_ comprises the revised versions of the original protocols as designed by [Annesha Bhoumik](https://www.merlin.uzh.ch/publication/show/21577). This package is necessary to generate the protocol-specific csv files that contain the required access information for loading the datasets.

## Setup

Assuming a Linux environment, a few steps are necessary to use the code on a local machine (note: if access to the IfI server **rolf** is given, these steps can be skipped since the entire project with all associated models and results is available in the project root directory _/home/user/msuter/projects/master-suter_). First, open a Command Line Interpreter (CLI) and clone the GitLab repository. Then, some dependencies must be installed (I recommend working with virtual environments using a manager as [Anaconda](https://www.anaconda.com/)).

- Depending on parameters like OS, language, and computing platform, install the PyTorch packages as described [here](https://pytorch.org/get-started/locally/). For example, on server **rolf**, using a locally activated conda environment, this defaults to `conda install pytorch torchvision cudatoolkit=11.3 -c pytorch`.

- `cd` into the root directory of the cloned repository (= project root directory) and install the two packages **eosa** and **imageNet_protocols** by running the commands `python -m pip install code/eosa/` and `python -m pip install code/imageNet_protocols/`.

## Evaluation of the Algorithms

The source code has been designed such that the algorithms can be configured and run using a CLI. Therefore, open a console and `cd` into the project root directory. The relevant code for performing the experiments is located in the module _experiments_ of the _eosa_ package. On server **rolf**, optionally regenerate the protocol-specific csv access files by running the command `python code/eosa/eosa/experiments/prepare_protocols.py`. On a local machine, access to the ILSVRC 2012 dataset is necessary to generate these csv access files. Therefore, the filesystem path to the dataset's root directory must be passed as an argument to the command (i.e., `python code/eosa/eosa/experiments/prepare_protocols.py --data_path <PATH_TO_ILSVRC2012_DATASET`).

Having these access files, the algorithms can now be evaluated on the different protocols. The files _eval_algos.py_ and _settings.py_ build the basis for running the algorithms. The configuration file _settings.py_ contains important configuration (hyper)parameters that are associated with the different algorithms. Hence, before evaluating a specific algorithm, possibly adjust the relevant parameters in this file (a description of these parameters is provided in the file itself). Afterwards, the script _eval_algos.py_ can be executed in combination with additional configuration options. Internally, this script relies on an argument parser object that performs the necessary checks on the passed arguments. The basic idea of this argument parser is to provide a mechanism that allows to run the experiments from a command line interface/interpreter (CLI) in a guided way. Specifically, for a selected algorithm, this parser ensures that all relevant options are specified and that the algorithm can only be configured in a valid way. Importantly, the argument parser object systematically guides the CLI user towards a correct configuration by pointing to the optional and required arguments. Therefore, the algorithm can be configured in a stepwise fashion. For example, running the command `python code/eosa/eosa/experiments/eval_algos.py` leads to a CLI output that points to the possible as well as the required arguments. Via the `-h` argument (i.e., the helper argument), a description of the arguments as well as the subcommands is provided. Since the argument parser is designed in a hierarchical fashion, different subcommands must be specified during the process. At every level, the helper argument offers guidance. In the end, a valid configuration starts either the training or the test procedure of the configured algorithm. The associated results can then be found in the directories as specified in the section _General Settings_ of the configuration file _settings.py_. By default, the results are stored in the project directory _results_ (located in the project root directory).

As an example, assuming correctly specified parameters in _settings.py_, the baseline model (using a ResNet50 architecture and the Adam optimizer) is trained (for 200 epochs) and tested on protocol 2 via the commands `python code/eosa/eosa/experiments/eval_algos.py -prot 2 -arch ResNet50 build_dnn train -opt Adam -opt_params_ok -e 200 base` and `python code/eosa/eosa/experiments/eval_algos.py -prot 2 -arch ResNet50 build_dnn test -mdl_pth_ok base` respectively.

Finally, the scripts _oscr_curves_per_algo.py_ and _oscr_curves_per_protocol.py_ provide functionality to generate the plots. These scripts provide a short configuration description.
